{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNix3vGvw7kXWJUTBK76bF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louis8ok1/DCGAN/blob/main/keras_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVdfNFTa9iTu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAuBMqm19Tc5"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from keras.datasets import mnist #手寫辨識\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NrYop5T9-vG"
      },
      "source": [
        "class DCGAN():\n",
        "  def __init__(self):\n",
        "    #Input Shape\n",
        "    self.img_shape = (28,28,1)\n",
        "    self.latent_dim = 100\n",
        "    optimizer = Adam(0.0002,0.5)\n",
        "\n",
        "    #Build and compile the discriminator\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss='binary_crossentropy',optimzer = optimizer,metrics={'output_discriminator'：'accuracy'}) \n",
        "\n",
        "    #Build the generator\n",
        "    self.generator = self.build_generator()\n",
        "\n",
        "    #The generator takes noise as input and generates fake imgs\n",
        "    z = Input(shape(self.latent_dim,))#z的dim為100\n",
        "    img = self.generator(z)\n",
        "\n",
        "    # For the combined model we will only train the generator\n",
        "    # 大問題!!!!!!!!!!(因為前面已經compile)\n",
        "    self.discriminator.trainable = False\n",
        "\n",
        "    # The discriminator takes generated images as input and determines validity\n",
        "    valid = self.discriminator(img)\n",
        "\n",
        "    #The combined model\n",
        "    #Trains the generator to fool the discriminator\n",
        "    self.combined = Model(z,valid)\n",
        "    self.combined.compile(loss='binary_crossentropy',optimzer = optimizer,metrics={'output_generator'：'accuracy'})\n",
        "    \n",
        "  def build_generator(self):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128*7*7,activation='relu',input_dim=self.latent_dim))\n",
        "    model.add(Reshape((7,7,128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Cov2D(64,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation('relu'))\n",
        "    #test是不是比較好\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64,kernel_size=3,padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(1,kernel_size=3,padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(self.latent_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise,img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,kernel_size=3,strides=2,input_dim=self.img_shape,padding='same'))\n",
        "    #alpha = Negative slope coefficient\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64,kernel_size=3,strides=2,padding='same'))\n",
        "    #在四周都填0\n",
        "    model.add(ZeroPadding2D(padding((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128,kernel_size=3,strides=2,padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    #FC layer\n",
        "    model.add(Conv2D(256,kernel_size=3,strides=1,padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img,validity)\n",
        "    #batch_size????????\n",
        "  def train(self,epochs,batch_size = 128,save_interval=50):\n",
        "\n",
        "    #Load data\n",
        "    (X_train,_),(_,_)=mnist.load_data()\n",
        "\n",
        "    #normalization\n",
        "    X_train\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}